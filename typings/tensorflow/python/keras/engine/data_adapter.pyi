import abc
from tensorflow.python.data.experimental.ops import cardinality as cardinality, distribute_options as distribute_options
from tensorflow.python.data.ops import dataset_ops as dataset_ops
from tensorflow.python.eager import context as context
from tensorflow.python.framework import dtypes as dtypes, errors as errors, ops as ops, smart_cond as smart_cond, sparse_tensor as sparse_tensor, tensor_shape as tensor_shape
from tensorflow.python.framework.ops import composite_tensor as composite_tensor
from tensorflow.python.keras import backend as backend
from tensorflow.python.keras.engine import training_utils as training_utils
from tensorflow.python.keras.utils import data_utils as data_utils
from tensorflow.python.ops import array_ops as array_ops, math_ops as math_ops, random_ops as random_ops, script_ops as script_ops
from tensorflow.python.util import nest as nest
from typing import Any, Optional

scalar_types: Any

class DataAdapter(metaclass=abc.ABCMeta):
    @staticmethod
    def can_handle(x: Any, y: Optional[Any] = ...) -> None: ...
    @abc.abstractmethod
    def __init__(self, x: Any, y: Optional[Any] = ..., **kwargs: Any) -> Any: ...
    @abc.abstractmethod
    def get_dataset(self) -> Any: ...
    @abc.abstractmethod
    def get_size(self) -> Any: ...
    @abc.abstractmethod
    def batch_size(self) -> Any: ...
    def representative_batch_size(self): ...
    @abc.abstractmethod
    def has_partial_batch(self) -> Any: ...
    @abc.abstractmethod
    def partial_batch_size(self) -> Any: ...
    @abc.abstractmethod
    def should_recreate_iterator(self) -> Any: ...
    def get_samples(self): ...
    def on_epoch_end(self) -> None: ...

class TensorLikeDataAdapter(DataAdapter):
    @staticmethod
    def can_handle(x: Any, y: Optional[Any] = ...): ...
    def __init__(self, x: Any, y: Optional[Any] = ..., sample_weights: Optional[Any] = ..., sample_weight_modes: Optional[Any] = ..., batch_size: Optional[Any] = ..., epochs: int = ..., steps: Optional[Any] = ..., shuffle: bool = ..., **kwargs: Any): ...
    def slice_inputs(self, indices_dataset: Any, inputs: Any): ...
    def get_dataset(self): ...
    def get_size(self): ...
    def batch_size(self): ...
    def has_partial_batch(self): ...
    def partial_batch_size(self): ...
    def should_recreate_iterator(self): ...

class GenericArrayLikeDataAdapter(TensorLikeDataAdapter):
    @staticmethod
    def can_handle(x: Any, y: Optional[Any] = ...): ...
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    def slice_inputs(self, indices_dataset: Any, inputs: Any): ...

class CompositeTensorDataAdapter(DataAdapter):
    @staticmethod
    def can_handle(x: Any, y: Optional[Any] = ...): ...
    def __init__(self, x: Any, y: Optional[Any] = ..., sample_weights: Optional[Any] = ..., sample_weight_modes: Optional[Any] = ..., batch_size: Optional[Any] = ..., steps: Optional[Any] = ..., shuffle: bool = ..., **kwargs: Any) -> None: ...
    def get_dataset(self): ...
    def get_size(self): ...
    def batch_size(self): ...
    def has_partial_batch(self): ...
    def partial_batch_size(self): ...
    def should_recreate_iterator(self): ...

class ListsOfScalarsDataAdapter(DataAdapter):
    @staticmethod
    def can_handle(x: Any, y: Optional[Any] = ...): ...
    def __init__(self, x: Any, y: Optional[Any] = ..., sample_weights: Optional[Any] = ..., sample_weight_modes: Optional[Any] = ..., batch_size: Optional[Any] = ..., shuffle: bool = ..., **kwargs: Any) -> None: ...
    def get_dataset(self): ...
    def get_size(self): ...
    def batch_size(self): ...
    def has_partial_batch(self): ...
    def partial_batch_size(self): ...
    def should_recreate_iterator(self): ...

class DatasetAdapter(DataAdapter):
    @staticmethod
    def can_handle(x: Any, y: Optional[Any] = ...): ...
    def __init__(self, x: Any, y: Optional[Any] = ..., sample_weights: Optional[Any] = ..., steps: Optional[Any] = ..., **kwargs: Any) -> None: ...
    def get_dataset(self): ...
    def get_size(self) -> None: ...
    def batch_size(self) -> None: ...
    def has_partial_batch(self): ...
    def partial_batch_size(self) -> None: ...
    def should_recreate_iterator(self): ...

class GeneratorDataAdapter(DataAdapter):
    @staticmethod
    def can_handle(x: Any, y: Optional[Any] = ...): ...
    def __init__(self, x: Any, y: Optional[Any] = ..., sample_weights: Optional[Any] = ..., workers: int = ..., use_multiprocessing: bool = ..., max_queue_size: int = ..., model: Optional[Any] = ..., **kwargs: Any): ...
    def get_dataset(self): ...
    def get_size(self) -> None: ...
    def batch_size(self) -> None: ...
    def representative_batch_size(self): ...
    def has_partial_batch(self): ...
    def partial_batch_size(self) -> None: ...
    def should_recreate_iterator(self): ...

class KerasSequenceAdapter(GeneratorDataAdapter):
    @staticmethod
    def can_handle(x: Any, y: Optional[Any] = ...): ...
    def __init__(self, x: Any, y: Optional[Any] = ..., sample_weights: Optional[Any] = ..., shuffle: bool = ..., workers: int = ..., use_multiprocessing: bool = ..., max_queue_size: int = ..., model: Optional[Any] = ..., **kwargs: Any) -> None: ...
    def get_size(self): ...
    def should_recreate_iterator(self): ...
    def on_epoch_end(self) -> None: ...

ALL_ADAPTER_CLS: Any

def select_data_adapter(x: Any, y: Any): ...
def is_none_or_empty(inputs: Any): ...
def broadcast_sample_weight_modes(target_structure: Any, sample_weight_modes: Any): ...
def assert_not_namedtuple(x: Any) -> None: ...

class DataHandler:
    def __init__(self, x: Any, y: Optional[Any] = ..., sample_weight: Optional[Any] = ..., batch_size: Optional[Any] = ..., steps_per_epoch: Optional[Any] = ..., initial_epoch: int = ..., epochs: int = ..., shuffle: bool = ..., class_weight: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ..., model: Optional[Any] = ...) -> None: ...
    def enumerate_epochs(self) -> None: ...
    def catch_stop_iteration(self) -> None: ...
    def steps(self) -> None: ...
    @property
    def inferred_steps(self): ...

def expand_1d(data: Any): ...
def train_validation_split(arrays: Any, validation_split: Any, shuffle: bool = ...): ...
def unpack_x_y_sample_weight(data: Any): ...
def pack_x_y_sample_weight(x: Any, y: Optional[Any] = ..., sample_weight: Optional[Any] = ...): ...
def single_batch_iterator(strategy: Any, x: Any, y: Optional[Any] = ..., sample_weight: Optional[Any] = ..., class_weight: Optional[Any] = ...): ...
