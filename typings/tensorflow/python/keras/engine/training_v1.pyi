from tensorflow.python import tf2 as tf2
from tensorflow.python.data.ops import dataset_ops as dataset_ops, iterator_ops as iterator_ops
from tensorflow.python.distribute import distribution_strategy_context as distribution_strategy_context
from tensorflow.python.eager import context as context, def_function as def_function, monitoring as monitoring
from tensorflow.python.framework import composite_tensor as composite_tensor, composite_tensor_utils as composite_tensor_utils, constant_op as constant_op, ops as ops, sparse_tensor as sparse_tensor, tensor_shape as tensor_shape, tensor_spec as tensor_spec, tensor_util as tensor_util, type_spec as type_spec
from tensorflow.python.keras import losses as losses, optimizers as optimizers
from tensorflow.python.keras.distribute import distributed_training_utils as distributed_training_utils
from tensorflow.python.keras.engine import network as network, training as training_lib, training_arrays as training_arrays, training_distributed as training_distributed, training_eager as training_eager, training_generator as training_generator, training_utils as training_utils
from tensorflow.python.keras.mixed_precision.experimental import loss_scale_optimizer as loss_scale_optimizer
from tensorflow.python.keras.optimizer_v2 import optimizer_v2 as optimizer_v2
from tensorflow.python.keras.saving.saved_model import model_serialization as model_serialization
from tensorflow.python.keras.utils import data_utils as data_utils, losses_utils as losses_utils
from tensorflow.python.keras.utils.mode_keys import ModeKeys as ModeKeys
from tensorflow.python.ops import array_ops as array_ops, math_ops as math_ops
from tensorflow.python.util import deprecation as deprecation, nest as nest, tf_inspect as tf_inspect
from tensorflow.python.util.compat import collections_abc as collections_abc
from typing import Any, Optional

class Model(training_lib.Model):
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    def get_weights(self): ...
    def load_weights(self, filepath: Any, by_name: bool = ..., skip_mismatch: bool = ...): ...
    loss: Any = ...
    loss_weights: Any = ...
    sample_weight_mode: Any = ...
    loss_functions: Any = ...
    train_function: Any = ...
    test_function: Any = ...
    predict_function: Any = ...
    def compile(self, optimizer: str = ..., loss: Optional[Any] = ..., metrics: Optional[Any] = ..., loss_weights: Optional[Any] = ..., sample_weight_mode: Optional[Any] = ..., weighted_metrics: Optional[Any] = ..., target_tensors: Optional[Any] = ..., distribute: Optional[Any] = ..., **kwargs: Any) -> None: ...
    @property
    def metrics(self): ...
    @property
    def metrics_names(self): ...
    @property
    def run_eagerly(self): ...
    @run_eagerly.setter
    def run_eagerly(self, value: Any) -> None: ...
    def fit(self, x: Optional[Any] = ..., y: Optional[Any] = ..., batch_size: Optional[Any] = ..., epochs: int = ..., verbose: int = ..., callbacks: Optional[Any] = ..., validation_split: float = ..., validation_data: Optional[Any] = ..., shuffle: bool = ..., class_weight: Optional[Any] = ..., sample_weight: Optional[Any] = ..., initial_epoch: int = ..., steps_per_epoch: Optional[Any] = ..., validation_steps: Optional[Any] = ..., validation_freq: int = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ..., **kwargs: Any): ...
    def evaluate(self, x: Optional[Any] = ..., y: Optional[Any] = ..., batch_size: Optional[Any] = ..., verbose: int = ..., sample_weight: Optional[Any] = ..., steps: Optional[Any] = ..., callbacks: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ...): ...
    def predict(self, x: Any, batch_size: Optional[Any] = ..., verbose: int = ..., steps: Optional[Any] = ..., callbacks: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ...): ...
    def reset_metrics(self) -> None: ...
    def train_on_batch(self, x: Any, y: Optional[Any] = ..., sample_weight: Optional[Any] = ..., class_weight: Optional[Any] = ..., reset_metrics: bool = ...): ...
    def test_on_batch(self, x: Any, y: Optional[Any] = ..., sample_weight: Optional[Any] = ..., reset_metrics: bool = ...): ...
    def predict_on_batch(self, x: Any): ...
    def fit_generator(self, generator: Any, steps_per_epoch: Optional[Any] = ..., epochs: int = ..., verbose: int = ..., callbacks: Optional[Any] = ..., validation_data: Optional[Any] = ..., validation_steps: Optional[Any] = ..., validation_freq: int = ..., class_weight: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ..., shuffle: bool = ..., initial_epoch: int = ...): ...
    def evaluate_generator(self, generator: Any, steps: Optional[Any] = ..., callbacks: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ..., verbose: int = ...): ...
    def predict_generator(self, generator: Any, steps: Optional[Any] = ..., callbacks: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ..., verbose: int = ...): ...
    @property
    def sample_weights(self): ...

class DistributedCallbackModel(Model):
    optimizer: Any = ...
    def __init__(self, model: Any) -> None: ...
    def set_original_model(self, orig_model: Any) -> None: ...
    def save_weights(self, filepath: Any, overwrite: bool = ..., save_format: Optional[Any] = ...) -> None: ...
    def save(self, filepath: Any, overwrite: bool = ..., include_optimizer: bool = ...) -> None: ...
    def load_weights(self, filepath: Any, by_name: bool = ...) -> None: ...
    def __getattr__(self, item: Any): ...

class _TrainingEndpoint:
    def __init__(self, output: Any, output_name: Any, loss_fn: Any, loss_weight: Optional[Any] = ..., training_target: Optional[Any] = ..., output_loss_metric: Optional[Any] = ..., sample_weight: Optional[Any] = ..., sample_weight_mode: Optional[Any] = ...) -> None: ...
    @property
    def output(self): ...
    @property
    def output_name(self): ...
    @property
    def shape(self): ...
    @property
    def loss_fn(self): ...
    @property
    def loss_weight(self): ...
    @loss_weight.setter
    def loss_weight(self, value: Any) -> None: ...
    @property
    def training_target(self): ...
    @training_target.setter
    def training_target(self, value: Any) -> None: ...
    def create_training_target(self, target: Any, run_eagerly: bool = ...) -> None: ...
    @property
    def output_loss_metric(self): ...
    @output_loss_metric.setter
    def output_loss_metric(self, value: Any) -> None: ...
    @property
    def sample_weight(self): ...
    @sample_weight.setter
    def sample_weight(self, value: Any) -> None: ...
    @property
    def sample_weight_mode(self): ...
    @sample_weight_mode.setter
    def sample_weight_mode(self, value: Any) -> None: ...
    def should_skip_target(self): ...
    def should_skip_target_weights(self): ...
    def has_training_target(self): ...
    def has_feedable_training_target(self): ...
    def loss_name(self): ...
    @property
    def feed_output_shape(self): ...
    def sample_weights_mismatch(self): ...
    def populate_sample_weight(self, sample_weight: Any, sample_weight_mode: Any) -> None: ...

class _TrainingTarget:
    def __init__(self, target: Any, feedable: bool = ..., skip_target_weights: bool = ...) -> None: ...
    @property
    def target(self): ...
    @property
    def feedable(self): ...
    @property
    def skip_target_weights(self): ...
