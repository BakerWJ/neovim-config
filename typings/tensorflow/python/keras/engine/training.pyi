from tensorflow.python.distribute import parameter_server_strategy as parameter_server_strategy
from tensorflow.python.eager import backprop as backprop, context as context, def_function as def_function, monitoring as monitoring
from tensorflow.python.framework import sparse_tensor as sparse_tensor
from tensorflow.python.keras import optimizers as optimizers
from tensorflow.python.keras.engine import compile_utils as compile_utils, data_adapter as data_adapter, network as network, training_utils as training_utils
from tensorflow.python.keras.saving.saved_model import model_serialization as model_serialization
from tensorflow.python.keras.utils import tf_utils as tf_utils, version_utils as version_utils
from tensorflow.python.keras.utils.mode_keys import ModeKeys as ModeKeys
from tensorflow.python.ops import array_ops as array_ops, sparse_ops as sparse_ops
from tensorflow.python.ops.ragged import ragged_concat_ops as ragged_concat_ops, ragged_tensor as ragged_tensor
from tensorflow.python.profiler import traceme as traceme
from tensorflow.python.util import deprecation as deprecation, nest as nest, tf_decorator as tf_decorator
from tensorflow.python.util.tf_export import keras_export as keras_export
from typing import Any, Optional

def enable_multi_worker(method: Any): ...
def disable_multi_worker(method: Any): ...

class Model(network.Network, version_utils.ModelVersionSelector):
    stop_training: bool = ...
    history: Any = ...
    compiled_loss: Any = ...
    compiled_metrics: Any = ...
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    def get_weights(self): ...
    def load_weights(self, filepath: Any, by_name: bool = ..., skip_mismatch: bool = ...): ...
    optimizer: Any = ...
    loss: Any = ...
    def compile(self, optimizer: str = ..., loss: Optional[Any] = ..., metrics: Optional[Any] = ..., loss_weights: Optional[Any] = ..., sample_weight_mode: Optional[Any] = ..., weighted_metrics: Optional[Any] = ..., **kwargs: Any) -> None: ...
    @property
    def metrics(self): ...
    @property
    def metrics_names(self): ...
    @property
    def distribute_strategy(self): ...
    @property
    def run_eagerly(self): ...
    @run_eagerly.setter
    def run_eagerly(self, value: Any) -> None: ...
    def train_step(self, data: Any): ...
    train_function: Any = ...
    def make_train_function(self): ...
    def fit(self, x: Optional[Any] = ..., y: Optional[Any] = ..., batch_size: Optional[Any] = ..., epochs: int = ..., verbose: int = ..., callbacks: Optional[Any] = ..., validation_split: float = ..., validation_data: Optional[Any] = ..., shuffle: bool = ..., class_weight: Optional[Any] = ..., sample_weight: Optional[Any] = ..., initial_epoch: int = ..., steps_per_epoch: Optional[Any] = ..., validation_steps: Optional[Any] = ..., validation_batch_size: Optional[Any] = ..., validation_freq: int = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ...): ...
    def test_step(self, data: Any): ...
    test_function: Any = ...
    def make_test_function(self): ...
    def evaluate(self, x: Optional[Any] = ..., y: Optional[Any] = ..., batch_size: Optional[Any] = ..., verbose: int = ..., sample_weight: Optional[Any] = ..., steps: Optional[Any] = ..., callbacks: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ..., return_dict: bool = ...): ...
    def predict_step(self, data: Any): ...
    predict_function: Any = ...
    def make_predict_function(self): ...
    def predict(self, x: Any, batch_size: Optional[Any] = ..., verbose: int = ..., steps: Optional[Any] = ..., callbacks: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ...): ...
    def reset_metrics(self) -> None: ...
    def train_on_batch(self, x: Any, y: Optional[Any] = ..., sample_weight: Optional[Any] = ..., class_weight: Optional[Any] = ..., reset_metrics: bool = ..., return_dict: bool = ...): ...
    def test_on_batch(self, x: Any, y: Optional[Any] = ..., sample_weight: Optional[Any] = ..., reset_metrics: bool = ..., return_dict: bool = ...): ...
    def predict_on_batch(self, x: Any): ...
    def fit_generator(self, generator: Any, steps_per_epoch: Optional[Any] = ..., epochs: int = ..., verbose: int = ..., callbacks: Optional[Any] = ..., validation_data: Optional[Any] = ..., validation_steps: Optional[Any] = ..., validation_freq: int = ..., class_weight: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ..., shuffle: bool = ..., initial_epoch: int = ...): ...
    def evaluate_generator(self, generator: Any, steps: Optional[Any] = ..., callbacks: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ..., verbose: int = ...): ...
    def predict_generator(self, generator: Any, steps: Optional[Any] = ..., callbacks: Optional[Any] = ..., max_queue_size: int = ..., workers: int = ..., use_multiprocessing: bool = ..., verbose: int = ...): ...

def reduce_per_replica(values: Any, strategy: Any, reduction: str = ...): ...
def concat(tensors: Any, axis: int = ...): ...
