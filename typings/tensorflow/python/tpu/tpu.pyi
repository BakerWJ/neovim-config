import enum
from tensorflow.core.framework import attr_value_pb2 as attr_value_pb2
from tensorflow.python.compiler.xla import xla as xla
from tensorflow.python.distribute import device_util as device_util, distribution_strategy_context as distribution_strategy_context
from tensorflow.python.framework import auto_control_deps as auto_control_deps, c_api_util as c_api_util, config as config, dtypes as dtypes, errors as errors, func_graph as func_graph, function as function, ops as ops, tensor_shape as tensor_shape
from tensorflow.python.ops import array_ops as array_ops, control_flow_ops as control_flow_ops, math_ops as math_ops, variable_scope as variable_scope
from tensorflow.python.tpu import tpu_function as tpu_function
from tensorflow.python.tpu.ops import tpu_ops as tpu_ops
from tensorflow.python.util import compat as compat, nest as nest
from tensorflow.python.util.compat import collections_abc as collections_abc
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any, Optional

def initialize_system(embedding_config: Optional[Any] = ..., job: Optional[Any] = ..., compilation_failure_closes_chips: bool = ...): ...
def initialize_system_for_tpu_embedding(embedding_config: Any, job: Optional[Any] = ...): ...
def shutdown_system(job: Optional[Any] = ...): ...
def core(num: Any): ...
def is_tpu_strategy(strategy: Any): ...
def tpu_replicated_input_resolver(op: Any, resource_reads: Any, resource_writes: Any): ...

class TPUReplicateContext(control_flow_ops.XLAControlFlowContext):
    def __init__(self, name: Any, num_replicas: Any, pivot: Any) -> None: ...
    def get_replicated_var_handle(self, name: Any, vars_: Any, is_mirrored: bool = ...): ...
    def report_unsupported_operations(self) -> None: ...
    def EnterGradientColocation(self, op: Any, gradient_uid: Any) -> None: ...
    def ExitGradientColocation(self, op: Any, gradient_uid: Any) -> None: ...
    def Enter(self) -> None: ...
    def HostComputeCore(self): ...
    def AddOp(self, op: Any) -> None: ...
    def AddValue(self, val: Any): ...
    def AddInnerOp(self, op: Any) -> None: ...
    @property
    def grad_state(self) -> None: ...
    @property
    def back_prop(self): ...
    def GetControlPivot(self): ...

class OutsideCompilationV2Context(control_flow_ops.ControlFlowContext):
    def __init__(self, name: Any) -> None: ...
    def AddOp(self, op: Any) -> None: ...
    def AddInnerOp(self, op: Any) -> None: ...
    def to_control_flow_context_def(self, context_def: Any, export_scope: Optional[Any] = ...) -> None: ...

def outside_compilation(computation: Any, *args: Any, **kwargs: Any): ...

class PaddingSpec(enum.IntEnum):
    AUTO: int = ...
    POWER_OF_TWO: int = ...

def replicate(computation: Any, inputs: Optional[Any] = ..., infeed_queue: Optional[Any] = ..., device_assignment: Optional[Any] = ..., name: Optional[Any] = ..., maximum_shapes: Optional[Any] = ..., padding_spec: Optional[Any] = ...): ...
def split_compile_and_replicate(computation: Any, inputs: Optional[Any] = ..., infeed_queue: Optional[Any] = ..., device_assignment: Optional[Any] = ..., name: Optional[Any] = ..., use_tpu: bool = ..., maximum_shapes: Optional[Any] = ..., padding_spec: Optional[Any] = ...): ...
def split_compile_and_shard(computation: Any, inputs: Optional[Any] = ..., num_shards: int = ..., input_shard_axes: Optional[Any] = ..., outputs_from_all_shards: bool = ..., output_shard_axes: Optional[Any] = ..., infeed_queue: Optional[Any] = ..., device_assignment: Optional[Any] = ..., name: Optional[Any] = ...): ...
def shard(computation: Any, inputs: Optional[Any] = ..., num_shards: int = ..., input_shard_axes: Optional[Any] = ..., outputs_from_all_shards: bool = ..., output_shard_axes: Optional[Any] = ..., infeed_queue: Optional[Any] = ..., device_assignment: Optional[Any] = ..., name: Optional[Any] = ...): ...
def batch_parallel(computation: Any, inputs: Optional[Any] = ..., num_shards: int = ..., infeed_queue: Optional[Any] = ..., device_assignment: Optional[Any] = ..., name: Optional[Any] = ...): ...
def rewrite(computation: Any, inputs: Optional[Any] = ..., infeed_queue: Optional[Any] = ..., device_assignment: Optional[Any] = ..., name: Optional[Any] = ...): ...
def under_tpu_inference_context(): ...

class _TPUInferenceContext(control_flow_ops.XLAControlFlowContext):
    def __init__(self, name: Any, check_ops: bool = ...) -> None: ...
    def AddOp(self, op: Any) -> None: ...
    def AddValue(self, val: Any): ...
    def AddInnerOp(self, op: Any) -> None: ...
    @property
    def grad_state(self) -> None: ...

def validate_inference_rewrite_for_variables(graph: Any) -> None: ...
def rewrite_for_inference(computation: Any, inputs: Optional[Any] = ..., infeed_queue: Optional[Any] = ..., device_assignment: Optional[Any] = ..., name: Optional[Any] = ...): ...
def prune_unconnected_ops_from_xla(prune_graph: Any) -> None: ...
