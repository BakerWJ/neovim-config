from tensorflow.python.ops.gen_resource_variable_ops import *
from tensorflow.core.framework import attr_value_pb2 as attr_value_pb2, variable_pb2 as variable_pb2
from tensorflow.python.client import pywrap_tf_session as pywrap_tf_session
from tensorflow.python.eager import context as context, tape as tape
from tensorflow.python.framework import constant_op as constant_op, cpp_shape_inference_pb2 as cpp_shape_inference_pb2, dtypes as dtypes, ops as ops, tensor_shape as tensor_shape, tensor_spec as tensor_spec
from tensorflow.python.ops import array_ops as array_ops, gen_array_ops as gen_array_ops, gen_logging_ops as gen_logging_ops, gen_resource_variable_ops as gen_resource_variable_ops, gen_state_ops as gen_state_ops, math_ops as math_ops, state_ops as state_ops, variables as variables
from tensorflow.python.util import compat as compat
from tensorflow.python.util.deprecation import deprecated as deprecated, deprecated_args as deprecated_args
from typing import Any, Optional

def get_resource_handle_data(graph_op: Any): ...
def get_eager_safe_handle_data(handle: Any): ...
def eager_safe_variable_handle(initial_value: Any, shape: Any, shared_name: Any, name: Any, graph_mode: Any): ...

class EagerResourceDeleter:
    def __init__(self, handle: Any, handle_device: Any) -> None: ...
    def __del__(self) -> None: ...

def shape_safe_assign_variable_handle(handle: Any, shape: Any, value: Any, name: Optional[Any] = ...): ...
def variable_accessed(variable: Any) -> None: ...

class BaseResourceVariable(variables.VariableV1):
    def __init__(self, trainable: Optional[Any] = ..., shape: Optional[Any] = ..., dtype: Optional[Any] = ..., handle: Optional[Any] = ..., constraint: Optional[Any] = ..., synchronization: Optional[Any] = ..., aggregation: Optional[Any] = ..., distribute_strategy: Optional[Any] = ..., name: Optional[Any] = ..., unique_id: Optional[Any] = ..., handle_name: Optional[Any] = ..., graph_element: Optional[Any] = ..., initial_value: Optional[Any] = ..., initializer_op: Optional[Any] = ..., is_initialized_op: Optional[Any] = ..., cached_value: Optional[Any] = ..., save_slice_info: Optional[Any] = ..., handle_deleter: Optional[Any] = ..., caching_device: Optional[Any] = ..., **unused_kwargs: Any) -> None: ...
    def __nonzero__(self): ...
    def __bool__(self): ...
    def __copy__(self): ...
    def __deepcopy__(self, memo: Any): ...
    @property
    def dtype(self): ...
    @property
    def device(self): ...
    @property
    def graph(self): ...
    @property
    def name(self): ...
    @property
    def shape(self): ...
    def set_shape(self, shape: Any) -> None: ...
    @property
    def create(self): ...
    @property
    def handle(self): ...
    def value(self): ...
    @property
    def initializer(self): ...
    @property
    def initial_value(self): ...
    @property
    def constraint(self): ...
    @property
    def op(self): ...
    @property
    def trainable(self): ...
    @property
    def synchronization(self): ...
    @property
    def aggregation(self): ...
    def eval(self, session: Optional[Any] = ...): ...
    def numpy(self): ...
    def count_up_to(self, limit: Any): ...
    def read_value(self): ...
    def sparse_read(self, indices: Any, name: Optional[Any] = ...): ...
    def gather_nd(self, indices: Any, name: Optional[Any] = ...): ...
    def to_proto(self, export_scope: Optional[Any] = ...): ...
    @staticmethod
    def from_proto(variable_def: Any, import_scope: Optional[Any] = ...): ...
    __array_priority__: int = ...
    def is_initialized(self, name: Optional[Any] = ...): ...
    def assign_sub(self, delta: Any, use_locking: Optional[Any] = ..., name: Optional[Any] = ..., read_value: bool = ...): ...
    def assign_add(self, delta: Any, use_locking: Optional[Any] = ..., name: Optional[Any] = ..., read_value: bool = ...): ...
    def assign(self, value: Any, use_locking: Optional[Any] = ..., name: Optional[Any] = ..., read_value: bool = ...): ...
    def __reduce__(self): ...
    def scatter_sub(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_add(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_max(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_min(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_mul(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_div(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_update(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def batch_scatter_update(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_nd_sub(self, indices: Any, updates: Any, name: Optional[Any] = ...): ...
    def scatter_nd_add(self, indices: Any, updates: Any, name: Optional[Any] = ...): ...
    def scatter_nd_update(self, indices: Any, updates: Any, name: Optional[Any] = ...): ...
    def __complex__(self): ...
    def __int__(self): ...
    def __long__(self): ...
    def __float__(self): ...
    def __iadd__(self, unused_other: Any) -> None: ...
    def __isub__(self, unused_other: Any) -> None: ...
    def __imul__(self, unused_other: Any) -> None: ...
    def __idiv__(self, unused_other: Any) -> None: ...
    def __itruediv__(self, unused_other: Any) -> None: ...
    def __irealdiv__(self, unused_other: Any) -> None: ...
    def __ipow__(self, unused_other: Any) -> None: ...

class ResourceVariable(BaseResourceVariable):
    def __init__(self, initial_value: Optional[Any] = ..., trainable: Optional[Any] = ..., collections: Optional[Any] = ..., validate_shape: bool = ..., caching_device: Optional[Any] = ..., name: Optional[Any] = ..., dtype: Optional[Any] = ..., variable_def: Optional[Any] = ..., import_scope: Optional[Any] = ..., constraint: Optional[Any] = ..., distribute_strategy: Optional[Any] = ..., synchronization: Optional[Any] = ..., aggregation: Optional[Any] = ..., shape: Optional[Any] = ...) -> None: ...

class UninitializedVariable(BaseResourceVariable):
    def __init__(self, trainable: Optional[Any] = ..., caching_device: Optional[Any] = ..., name: Optional[Any] = ..., shape: Optional[Any] = ..., dtype: Optional[Any] = ..., constraint: Optional[Any] = ..., synchronization: Optional[Any] = ..., aggregation: Optional[Any] = ..., extra_handle_data: Optional[Any] = ..., distribute_strategy: Optional[Any] = ..., **unused_kwargs: Any) -> None: ...

class _UnreadVariable(BaseResourceVariable):
    def __init__(self, handle: Any, dtype: Any, shape: Any, in_graph_mode: Any, deleter: Any, parent_op: Any, unique_id: Any) -> None: ...
    @property
    def name(self): ...
    def value(self): ...
    def read_value(self): ...
    def assign_sub(self, delta: Any, use_locking: Optional[Any] = ..., name: Optional[Any] = ..., read_value: bool = ...): ...
    def assign_add(self, delta: Any, use_locking: Optional[Any] = ..., name: Optional[Any] = ..., read_value: bool = ...): ...
    def assign(self, value: Any, use_locking: Optional[Any] = ..., name: Optional[Any] = ..., read_value: bool = ...): ...
    def scatter_sub(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_add(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_max(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_min(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_mul(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_div(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_update(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def batch_scatter_update(self, sparse_delta: Any, use_locking: bool = ..., name: Optional[Any] = ...): ...
    def scatter_nd_sub(self, indices: Any, updates: Any, name: Optional[Any] = ...): ...
    def scatter_nd_add(self, indices: Any, updates: Any, name: Optional[Any] = ...): ...
    def scatter_nd_update(self, indices: Any, updates: Any, name: Optional[Any] = ...): ...
    @property
    def op(self): ...

def variable_shape(handle: Any, out_type: Any = ...): ...
def is_resource_variable(var: Any): ...
def copy_to_graph_uninitialized(var: Any): ...

class VariableSpec(tensor_spec.DenseSpec):
    value_type: Any = ...
