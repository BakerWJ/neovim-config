from tensorflow.python.util.deprecation import deprecated_endpoints as deprecated_endpoints
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any, Optional

def assert_cardinality_dataset(input_dataset: Any, cardinality: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

AssertCardinalityDataset: Any

def assert_cardinality_dataset_eager_fallback(input_dataset: Any, cardinality: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def assert_next_dataset(input_dataset: Any, transformations: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

AssertNextDataset: Any

def assert_next_dataset_eager_fallback(input_dataset: Any, transformations: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def auto_shard_dataset(input_dataset: Any, num_workers: Any, index: Any, output_types: Any, output_shapes: Any, auto_shard_policy: int = ..., name: Optional[Any] = ...): ...

AutoShardDataset: Any

def auto_shard_dataset_eager_fallback(input_dataset: Any, num_workers: Any, index: Any, output_types: Any, output_shapes: Any, auto_shard_policy: Any, name: Any, ctx: Any): ...
def bytes_produced_stats_dataset(input_dataset: Any, tag: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

BytesProducedStatsDataset: Any

def bytes_produced_stats_dataset_eager_fallback(input_dataset: Any, tag: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def csv_dataset(filenames: Any, compression_type: Any, buffer_size: Any, header: Any, field_delim: Any, use_quote_delim: Any, na_value: Any, select_cols: Any, record_defaults: Any, output_shapes: Any, name: Optional[Any] = ...): ...

CSVDataset: Any

def csv_dataset_eager_fallback(filenames: Any, compression_type: Any, buffer_size: Any, header: Any, field_delim: Any, use_quote_delim: Any, na_value: Any, select_cols: Any, record_defaults: Any, output_shapes: Any, name: Any, ctx: Any): ...
def choose_fastest_branch_dataset(input_dataset: Any, ratio_numerator: Any, ratio_denominator: Any, other_arguments: Any, num_elements_per_branch: Any, branches: Any, other_arguments_lengths: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ChooseFastestBranchDataset: Any

def choose_fastest_branch_dataset_eager_fallback(input_dataset: Any, ratio_numerator: Any, ratio_denominator: Any, other_arguments: Any, num_elements_per_branch: Any, branches: Any, other_arguments_lengths: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def choose_fastest_dataset(input_datasets: Any, num_experiments: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ChooseFastestDataset: Any

def choose_fastest_dataset_eager_fallback(input_datasets: Any, num_experiments: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def dataset_cardinality(input_dataset: Any, name: Optional[Any] = ...): ...

DatasetCardinality: Any

def dataset_cardinality_eager_fallback(input_dataset: Any, name: Any, ctx: Any): ...
def dataset_from_graph(graph_def: Any, name: Optional[Any] = ...): ...

DatasetFromGraph: Any

def dataset_from_graph_eager_fallback(graph_def: Any, name: Any, ctx: Any): ...
def dataset_to_tf_record(input_dataset: Any, filename: Any, compression_type: Any, name: Optional[Any] = ...): ...

DatasetToTFRecord: Any

def dataset_to_tf_record_eager_fallback(input_dataset: Any, filename: Any, compression_type: Any, name: Any, ctx: Any): ...
def dense_to_sparse_batch_dataset(input_dataset: Any, batch_size: Any, row_shape: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

DenseToSparseBatchDataset: Any

def dense_to_sparse_batch_dataset_eager_fallback(input_dataset: Any, batch_size: Any, row_shape: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def directed_interleave_dataset(selector_input_dataset: Any, data_input_datasets: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

DirectedInterleaveDataset: Any

def directed_interleave_dataset_eager_fallback(selector_input_dataset: Any, data_input_datasets: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_assert_next_dataset(input_dataset: Any, transformations: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalAssertNextDataset: Any

def experimental_assert_next_dataset_eager_fallback(input_dataset: Any, transformations: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_auto_shard_dataset(input_dataset: Any, num_workers: Any, index: Any, output_types: Any, output_shapes: Any, auto_shard_policy: int = ..., name: Optional[Any] = ...): ...

ExperimentalAutoShardDataset: Any

def experimental_auto_shard_dataset_eager_fallback(input_dataset: Any, num_workers: Any, index: Any, output_types: Any, output_shapes: Any, auto_shard_policy: Any, name: Any, ctx: Any): ...
def experimental_bytes_produced_stats_dataset(input_dataset: Any, tag: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalBytesProducedStatsDataset: Any

def experimental_bytes_produced_stats_dataset_eager_fallback(input_dataset: Any, tag: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_csv_dataset(filenames: Any, compression_type: Any, buffer_size: Any, header: Any, field_delim: Any, use_quote_delim: Any, na_value: Any, select_cols: Any, record_defaults: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalCSVDataset: Any

def experimental_csv_dataset_eager_fallback(filenames: Any, compression_type: Any, buffer_size: Any, header: Any, field_delim: Any, use_quote_delim: Any, na_value: Any, select_cols: Any, record_defaults: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_choose_fastest_dataset(input_datasets: Any, num_experiments: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalChooseFastestDataset: Any

def experimental_choose_fastest_dataset_eager_fallback(input_datasets: Any, num_experiments: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_dataset_cardinality(input_dataset: Any, name: Optional[Any] = ...): ...

ExperimentalDatasetCardinality: Any

def experimental_dataset_cardinality_eager_fallback(input_dataset: Any, name: Any, ctx: Any): ...
def experimental_dataset_to_tf_record(input_dataset: Any, filename: Any, compression_type: Any, name: Optional[Any] = ...): ...

ExperimentalDatasetToTFRecord: Any

def experimental_dataset_to_tf_record_eager_fallback(input_dataset: Any, filename: Any, compression_type: Any, name: Any, ctx: Any): ...
def experimental_dense_to_sparse_batch_dataset(input_dataset: Any, batch_size: Any, row_shape: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalDenseToSparseBatchDataset: Any

def experimental_dense_to_sparse_batch_dataset_eager_fallback(input_dataset: Any, batch_size: Any, row_shape: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_directed_interleave_dataset(selector_input_dataset: Any, data_input_datasets: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalDirectedInterleaveDataset: Any

def experimental_directed_interleave_dataset_eager_fallback(selector_input_dataset: Any, data_input_datasets: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_group_by_reducer_dataset(input_dataset: Any, key_func_other_arguments: Any, init_func_other_arguments: Any, reduce_func_other_arguments: Any, finalize_func_other_arguments: Any, key_func: Any, init_func: Any, reduce_func: Any, finalize_func: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalGroupByReducerDataset: Any

def experimental_group_by_reducer_dataset_eager_fallback(input_dataset: Any, key_func_other_arguments: Any, init_func_other_arguments: Any, reduce_func_other_arguments: Any, finalize_func_other_arguments: Any, key_func: Any, init_func: Any, reduce_func: Any, finalize_func: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_group_by_window_dataset(input_dataset: Any, key_func_other_arguments: Any, reduce_func_other_arguments: Any, window_size_func_other_arguments: Any, key_func: Any, reduce_func: Any, window_size_func: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalGroupByWindowDataset: Any

def experimental_group_by_window_dataset_eager_fallback(input_dataset: Any, key_func_other_arguments: Any, reduce_func_other_arguments: Any, window_size_func_other_arguments: Any, key_func: Any, reduce_func: Any, window_size_func: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_ignore_errors_dataset(input_dataset: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalIgnoreErrorsDataset: Any

def experimental_ignore_errors_dataset_eager_fallback(input_dataset: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_iterator_get_device(resource: Any, name: Optional[Any] = ...): ...

ExperimentalIteratorGetDevice: Any

def experimental_iterator_get_device_eager_fallback(resource: Any, name: Any, ctx: Any): ...
def experimental_lmdb_dataset(filenames: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalLMDBDataset: Any

def experimental_lmdb_dataset_eager_fallback(filenames: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_latency_stats_dataset(input_dataset: Any, tag: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalLatencyStatsDataset: Any

def experimental_latency_stats_dataset_eager_fallback(input_dataset: Any, tag: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_map_and_batch_dataset(input_dataset: Any, other_arguments: Any, batch_size: Any, num_parallel_calls: Any, drop_remainder: Any, f: Any, output_types: Any, output_shapes: Any, preserve_cardinality: bool = ..., name: Optional[Any] = ...): ...

ExperimentalMapAndBatchDataset: Any

def experimental_map_and_batch_dataset_eager_fallback(input_dataset: Any, other_arguments: Any, batch_size: Any, num_parallel_calls: Any, drop_remainder: Any, f: Any, output_types: Any, output_shapes: Any, preserve_cardinality: Any, name: Any, ctx: Any): ...
def experimental_map_dataset(input_dataset: Any, other_arguments: Any, f: Any, output_types: Any, output_shapes: Any, use_inter_op_parallelism: bool = ..., preserve_cardinality: bool = ..., name: Optional[Any] = ...): ...

ExperimentalMapDataset: Any

def experimental_map_dataset_eager_fallback(input_dataset: Any, other_arguments: Any, f: Any, output_types: Any, output_shapes: Any, use_inter_op_parallelism: Any, preserve_cardinality: Any, name: Any, ctx: Any): ...
def experimental_matching_files_dataset(patterns: Any, name: Optional[Any] = ...): ...

ExperimentalMatchingFilesDataset: Any

def experimental_matching_files_dataset_eager_fallback(patterns: Any, name: Any, ctx: Any): ...
def experimental_max_intra_op_parallelism_dataset(input_dataset: Any, max_intra_op_parallelism: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalMaxIntraOpParallelismDataset: Any

def experimental_max_intra_op_parallelism_dataset_eager_fallback(input_dataset: Any, max_intra_op_parallelism: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_non_serializable_dataset(input_dataset: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalNonSerializableDataset: Any

def experimental_non_serializable_dataset_eager_fallback(input_dataset: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_parallel_interleave_dataset(input_dataset: Any, other_arguments: Any, cycle_length: Any, block_length: Any, sloppy: Any, buffer_output_elements: Any, prefetch_input_elements: Any, f: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalParallelInterleaveDataset: Any

def experimental_parallel_interleave_dataset_eager_fallback(input_dataset: Any, other_arguments: Any, cycle_length: Any, block_length: Any, sloppy: Any, buffer_output_elements: Any, prefetch_input_elements: Any, f: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_parse_example_dataset(input_dataset: Any, num_parallel_calls: Any, dense_defaults: Any, sparse_keys: Any, dense_keys: Any, sparse_types: Any, dense_shapes: Any, output_types: Any, output_shapes: Any, sloppy: bool = ..., name: Optional[Any] = ...): ...

ExperimentalParseExampleDataset: Any

def experimental_parse_example_dataset_eager_fallback(input_dataset: Any, num_parallel_calls: Any, dense_defaults: Any, sparse_keys: Any, dense_keys: Any, sparse_types: Any, dense_shapes: Any, output_types: Any, output_shapes: Any, sloppy: Any, name: Any, ctx: Any): ...
def experimental_private_thread_pool_dataset(input_dataset: Any, num_threads: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalPrivateThreadPoolDataset: Any

def experimental_private_thread_pool_dataset_eager_fallback(input_dataset: Any, num_threads: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_random_dataset(seed: Any, seed2: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalRandomDataset: Any

def experimental_random_dataset_eager_fallback(seed: Any, seed2: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_rebatch_dataset(input_dataset: Any, num_replicas: Any, output_types: Any, output_shapes: Any, use_fallback: bool = ..., name: Optional[Any] = ...): ...

ExperimentalRebatchDataset: Any

def experimental_rebatch_dataset_eager_fallback(input_dataset: Any, num_replicas: Any, output_types: Any, output_shapes: Any, use_fallback: Any, name: Any, ctx: Any): ...
def experimental_scan_dataset(input_dataset: Any, initial_state: Any, other_arguments: Any, f: Any, output_types: Any, output_shapes: Any, preserve_cardinality: bool = ..., name: Optional[Any] = ...): ...

ExperimentalScanDataset: Any

def experimental_scan_dataset_eager_fallback(input_dataset: Any, initial_state: Any, other_arguments: Any, f: Any, output_types: Any, output_shapes: Any, preserve_cardinality: Any, name: Any, ctx: Any): ...
def experimental_set_stats_aggregator_dataset(input_dataset: Any, stats_aggregator: Any, tag: Any, counter_prefix: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalSetStatsAggregatorDataset: Any

def experimental_set_stats_aggregator_dataset_eager_fallback(input_dataset: Any, stats_aggregator: Any, tag: Any, counter_prefix: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_sleep_dataset(input_dataset: Any, sleep_microseconds: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalSleepDataset: Any

def experimental_sleep_dataset_eager_fallback(input_dataset: Any, sleep_microseconds: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_sliding_window_dataset(input_dataset: Any, window_size: Any, window_shift: Any, window_stride: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalSlidingWindowDataset: Any

def experimental_sliding_window_dataset_eager_fallback(input_dataset: Any, window_size: Any, window_shift: Any, window_stride: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_sql_dataset(driver_name: Any, data_source_name: Any, query: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalSqlDataset: Any

def experimental_sql_dataset_eager_fallback(driver_name: Any, data_source_name: Any, query: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_stats_aggregator_handle(container: str = ..., shared_name: str = ..., name: Optional[Any] = ...): ...

ExperimentalStatsAggregatorHandle: Any

def experimental_stats_aggregator_handle_eager_fallback(container: Any, shared_name: Any, name: Any, ctx: Any): ...
def experimental_stats_aggregator_summary(iterator: Any, name: Optional[Any] = ...): ...

ExperimentalStatsAggregatorSummary: Any

def experimental_stats_aggregator_summary_eager_fallback(iterator: Any, name: Any, ctx: Any): ...
def experimental_take_while_dataset(input_dataset: Any, other_arguments: Any, predicate: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalTakeWhileDataset: Any

def experimental_take_while_dataset_eager_fallback(input_dataset: Any, other_arguments: Any, predicate: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_thread_pool_dataset(input_dataset: Any, thread_pool: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalThreadPoolDataset: Any

def experimental_thread_pool_dataset_eager_fallback(input_dataset: Any, thread_pool: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_thread_pool_handle(num_threads: Any, display_name: Any, max_intra_op_parallelism: int = ..., container: str = ..., shared_name: str = ..., name: Optional[Any] = ...): ...

ExperimentalThreadPoolHandle: Any

def experimental_thread_pool_handle_eager_fallback(num_threads: Any, display_name: Any, max_intra_op_parallelism: Any, container: Any, shared_name: Any, name: Any, ctx: Any): ...
def experimental_unbatch_dataset(input_dataset: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalUnbatchDataset: Any

def experimental_unbatch_dataset_eager_fallback(input_dataset: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def experimental_unique_dataset(input_dataset: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ExperimentalUniqueDataset: Any

def experimental_unique_dataset_eager_fallback(input_dataset: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def group_by_reducer_dataset(input_dataset: Any, key_func_other_arguments: Any, init_func_other_arguments: Any, reduce_func_other_arguments: Any, finalize_func_other_arguments: Any, key_func: Any, init_func: Any, reduce_func: Any, finalize_func: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

GroupByReducerDataset: Any

def group_by_reducer_dataset_eager_fallback(input_dataset: Any, key_func_other_arguments: Any, init_func_other_arguments: Any, reduce_func_other_arguments: Any, finalize_func_other_arguments: Any, key_func: Any, init_func: Any, reduce_func: Any, finalize_func: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def group_by_window_dataset(input_dataset: Any, key_func_other_arguments: Any, reduce_func_other_arguments: Any, window_size_func_other_arguments: Any, key_func: Any, reduce_func: Any, window_size_func: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

GroupByWindowDataset: Any

def group_by_window_dataset_eager_fallback(input_dataset: Any, key_func_other_arguments: Any, reduce_func_other_arguments: Any, window_size_func_other_arguments: Any, key_func: Any, reduce_func: Any, window_size_func: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def ignore_errors_dataset(input_dataset: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

IgnoreErrorsDataset: Any

def ignore_errors_dataset_eager_fallback(input_dataset: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def iterator_get_device(resource: Any, name: Optional[Any] = ...): ...

IteratorGetDevice: Any

def iterator_get_device_eager_fallback(resource: Any, name: Any, ctx: Any): ...
def lmdb_dataset(filenames: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

LMDBDataset: Any

def lmdb_dataset_eager_fallback(filenames: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def latency_stats_dataset(input_dataset: Any, tag: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

LatencyStatsDataset: Any

def latency_stats_dataset_eager_fallback(input_dataset: Any, tag: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def legacy_parallel_interleave_dataset_v2(input_dataset: Any, other_arguments: Any, cycle_length: Any, block_length: Any, buffer_output_elements: Any, prefetch_input_elements: Any, f: Any, output_types: Any, output_shapes: Any, deterministic: str = ..., name: Optional[Any] = ...): ...

LegacyParallelInterleaveDatasetV2: Any

def legacy_parallel_interleave_dataset_v2_eager_fallback(input_dataset: Any, other_arguments: Any, cycle_length: Any, block_length: Any, buffer_output_elements: Any, prefetch_input_elements: Any, f: Any, output_types: Any, output_shapes: Any, deterministic: Any, name: Any, ctx: Any): ...
def map_and_batch_dataset(input_dataset: Any, other_arguments: Any, batch_size: Any, num_parallel_calls: Any, drop_remainder: Any, f: Any, output_types: Any, output_shapes: Any, preserve_cardinality: bool = ..., name: Optional[Any] = ...): ...

MapAndBatchDataset: Any

def map_and_batch_dataset_eager_fallback(input_dataset: Any, other_arguments: Any, batch_size: Any, num_parallel_calls: Any, drop_remainder: Any, f: Any, output_types: Any, output_shapes: Any, preserve_cardinality: Any, name: Any, ctx: Any): ...
def matching_files_dataset(patterns: Any, name: Optional[Any] = ...): ...

MatchingFilesDataset: Any

def matching_files_dataset_eager_fallback(patterns: Any, name: Any, ctx: Any): ...
def max_intra_op_parallelism_dataset(input_dataset: Any, max_intra_op_parallelism: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

MaxIntraOpParallelismDataset: Any

def max_intra_op_parallelism_dataset_eager_fallback(input_dataset: Any, max_intra_op_parallelism: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def non_serializable_dataset(input_dataset: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

NonSerializableDataset: Any

def non_serializable_dataset_eager_fallback(input_dataset: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def parallel_interleave_dataset(input_dataset: Any, other_arguments: Any, cycle_length: Any, block_length: Any, sloppy: Any, buffer_output_elements: Any, prefetch_input_elements: Any, f: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ParallelInterleaveDataset: Any

def parallel_interleave_dataset_eager_fallback(input_dataset: Any, other_arguments: Any, cycle_length: Any, block_length: Any, sloppy: Any, buffer_output_elements: Any, prefetch_input_elements: Any, f: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def parse_example_dataset(input_dataset: Any, num_parallel_calls: Any, dense_defaults: Any, sparse_keys: Any, dense_keys: Any, sparse_types: Any, dense_shapes: Any, output_types: Any, output_shapes: Any, sloppy: bool = ..., ragged_keys: Any = ..., ragged_value_types: Any = ..., ragged_split_types: Any = ..., name: Optional[Any] = ...): ...

ParseExampleDataset: Any

def parse_example_dataset_eager_fallback(input_dataset: Any, num_parallel_calls: Any, dense_defaults: Any, sparse_keys: Any, dense_keys: Any, sparse_types: Any, dense_shapes: Any, output_types: Any, output_shapes: Any, sloppy: Any, ragged_keys: Any, ragged_value_types: Any, ragged_split_types: Any, name: Any, ctx: Any): ...
def parse_example_dataset_v2(input_dataset: Any, num_parallel_calls: Any, dense_defaults: Any, sparse_keys: Any, dense_keys: Any, sparse_types: Any, dense_shapes: Any, output_types: Any, output_shapes: Any, deterministic: str = ..., ragged_keys: Any = ..., ragged_value_types: Any = ..., ragged_split_types: Any = ..., name: Optional[Any] = ...): ...

ParseExampleDatasetV2: Any

def parse_example_dataset_v2_eager_fallback(input_dataset: Any, num_parallel_calls: Any, dense_defaults: Any, sparse_keys: Any, dense_keys: Any, sparse_types: Any, dense_shapes: Any, output_types: Any, output_shapes: Any, deterministic: Any, ragged_keys: Any, ragged_value_types: Any, ragged_split_types: Any, name: Any, ctx: Any): ...
def private_thread_pool_dataset(input_dataset: Any, num_threads: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

PrivateThreadPoolDataset: Any

def private_thread_pool_dataset_eager_fallback(input_dataset: Any, num_threads: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def random_dataset(seed: Any, seed2: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

RandomDataset: Any

def random_dataset_eager_fallback(seed: Any, seed2: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def rebatch_dataset(input_dataset: Any, num_replicas: Any, output_types: Any, output_shapes: Any, use_fallback: bool = ..., name: Optional[Any] = ...): ...

RebatchDataset: Any

def rebatch_dataset_eager_fallback(input_dataset: Any, num_replicas: Any, output_types: Any, output_shapes: Any, use_fallback: Any, name: Any, ctx: Any): ...
def sampling_dataset(input_dataset: Any, rate: Any, seed: Any, seed2: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

SamplingDataset: Any

def sampling_dataset_eager_fallback(input_dataset: Any, rate: Any, seed: Any, seed2: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def scan_dataset(input_dataset: Any, initial_state: Any, other_arguments: Any, f: Any, output_types: Any, output_shapes: Any, preserve_cardinality: bool = ..., use_default_device: bool = ..., name: Optional[Any] = ...): ...

ScanDataset: Any

def scan_dataset_eager_fallback(input_dataset: Any, initial_state: Any, other_arguments: Any, f: Any, output_types: Any, output_shapes: Any, preserve_cardinality: Any, use_default_device: Any, name: Any, ctx: Any): ...
def set_stats_aggregator_dataset(input_dataset: Any, stats_aggregator: Any, tag: Any, counter_prefix: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

SetStatsAggregatorDataset: Any

def set_stats_aggregator_dataset_eager_fallback(input_dataset: Any, stats_aggregator: Any, tag: Any, counter_prefix: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def sleep_dataset(input_dataset: Any, sleep_microseconds: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

SleepDataset: Any

def sleep_dataset_eager_fallback(input_dataset: Any, sleep_microseconds: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def sliding_window_dataset(input_dataset: Any, window_size: Any, window_shift: Any, window_stride: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

SlidingWindowDataset: Any

def sliding_window_dataset_eager_fallback(input_dataset: Any, window_size: Any, window_shift: Any, window_stride: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def snapshot_dataset(input_dataset: Any, path: Any, output_types: Any, output_shapes: Any, compression: str = ..., reader_path_prefix: str = ..., writer_path_prefix: str = ..., shard_size_bytes: int = ..., pending_snapshot_expiry_seconds: int = ..., num_reader_threads: int = ..., reader_buffer_size: int = ..., num_writer_threads: int = ..., writer_buffer_size: int = ..., shuffle_on_read: bool = ..., seed: int = ..., seed2: int = ..., mode: str = ..., snapshot_name: str = ..., name: Optional[Any] = ...): ...

SnapshotDataset: Any

def snapshot_dataset_eager_fallback(input_dataset: Any, path: Any, output_types: Any, output_shapes: Any, compression: Any, reader_path_prefix: Any, writer_path_prefix: Any, shard_size_bytes: Any, pending_snapshot_expiry_seconds: Any, num_reader_threads: Any, reader_buffer_size: Any, num_writer_threads: Any, writer_buffer_size: Any, shuffle_on_read: Any, seed: Any, seed2: Any, mode: Any, snapshot_name: Any, name: Any, ctx: Any): ...
def sql_dataset(driver_name: Any, data_source_name: Any, query: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

SqlDataset: Any

def sql_dataset_eager_fallback(driver_name: Any, data_source_name: Any, query: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def stats_aggregator_handle(container: str = ..., shared_name: str = ..., name: Optional[Any] = ...): ...

StatsAggregatorHandle: Any

def stats_aggregator_handle_eager_fallback(container: Any, shared_name: Any, name: Any, ctx: Any): ...
def stats_aggregator_handle_v2(container: str = ..., shared_name: str = ..., name: Optional[Any] = ...): ...

StatsAggregatorHandleV2: Any

def stats_aggregator_handle_v2_eager_fallback(container: Any, shared_name: Any, name: Any, ctx: Any): ...
def stats_aggregator_set_summary_writer(stats_aggregator: Any, summary: Any, name: Optional[Any] = ...): ...

StatsAggregatorSetSummaryWriter: Any

def stats_aggregator_set_summary_writer_eager_fallback(stats_aggregator: Any, summary: Any, name: Any, ctx: Any): ...
def stats_aggregator_summary(iterator: Any, name: Optional[Any] = ...): ...

StatsAggregatorSummary: Any

def stats_aggregator_summary_eager_fallback(iterator: Any, name: Any, ctx: Any): ...
def take_while_dataset(input_dataset: Any, other_arguments: Any, predicate: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

TakeWhileDataset: Any

def take_while_dataset_eager_fallback(input_dataset: Any, other_arguments: Any, predicate: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def thread_pool_dataset(input_dataset: Any, thread_pool: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

ThreadPoolDataset: Any

def thread_pool_dataset_eager_fallback(input_dataset: Any, thread_pool: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def thread_pool_handle(num_threads: Any, display_name: Any, max_intra_op_parallelism: int = ..., container: str = ..., shared_name: str = ..., name: Optional[Any] = ...): ...

ThreadPoolHandle: Any

def thread_pool_handle_eager_fallback(num_threads: Any, display_name: Any, max_intra_op_parallelism: Any, container: Any, shared_name: Any, name: Any, ctx: Any): ...
def unbatch_dataset(input_dataset: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

UnbatchDataset: Any

def unbatch_dataset_eager_fallback(input_dataset: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
def unique_dataset(input_dataset: Any, output_types: Any, output_shapes: Any, name: Optional[Any] = ...): ...

UniqueDataset: Any

def unique_dataset_eager_fallback(input_dataset: Any, output_types: Any, output_shapes: Any, name: Any, ctx: Any): ...
