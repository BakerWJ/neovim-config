from collections import namedtuple
from tensorflow.python.util.deprecation import deprecated_endpoints as deprecated_endpoints
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any, Optional

def avg_pool(value: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

AvgPool: Any

def avg_pool_eager_fallback(value: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def avg_pool3d(input: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

AvgPool3D: Any

def avg_pool3d_eager_fallback(input: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def avg_pool3d_grad(orig_input_shape: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

AvgPool3DGrad: Any

def avg_pool3d_grad_eager_fallback(orig_input_shape: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def avg_pool_grad(orig_input_shape: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

AvgPoolGrad: Any

def avg_pool_grad_eager_fallback(orig_input_shape: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...

BatchNormWithGlobalNormalization: Any

_BatchNormWithGlobalNormalizationGradOutput = namedtuple('BatchNormWithGlobalNormalizationGrad', ['dx', 'dm', 'dv', 'db', 'dg'])

def batch_norm_with_global_normalization_grad(t: Any, m: Any, v: Any, gamma: Any, backprop: Any, variance_epsilon: Any, scale_after_normalization: Any, name: Optional[Any] = ...): ...

BatchNormWithGlobalNormalizationGrad: Any

def batch_norm_with_global_normalization_grad_eager_fallback(t: Any, m: Any, v: Any, gamma: Any, backprop: Any, variance_epsilon: Any, scale_after_normalization: Any, name: Any, ctx: Any): ...
def bias_add(value: Any, bias: Any, data_format: str = ..., name: Optional[Any] = ...): ...

BiasAdd: Any

def bias_add_eager_fallback(value: Any, bias: Any, data_format: Any, name: Any, ctx: Any): ...
def bias_add_grad(out_backprop: Any, data_format: str = ..., name: Optional[Any] = ...): ...

BiasAddGrad: Any

def bias_add_grad_eager_fallback(out_backprop: Any, data_format: Any, name: Any, ctx: Any): ...
def bias_add_v1(value: Any, bias: Any, name: Optional[Any] = ...): ...

BiasAddV1: Any

def bias_add_v1_eager_fallback(value: Any, bias: Any, name: Any, ctx: Any): ...
def conv2d(input: Any, filter: Any, strides: Any, padding: Any, use_cudnn_on_gpu: bool = ..., explicit_paddings: Any = ..., data_format: str = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

Conv2D: Any

def conv2d_eager_fallback(input: Any, filter: Any, strides: Any, padding: Any, use_cudnn_on_gpu: Any, explicit_paddings: Any, data_format: Any, dilations: Any, name: Any, ctx: Any): ...
def conv2d_backprop_filter(input: Any, filter_sizes: Any, out_backprop: Any, strides: Any, padding: Any, use_cudnn_on_gpu: bool = ..., explicit_paddings: Any = ..., data_format: str = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

Conv2DBackpropFilter: Any

def conv2d_backprop_filter_eager_fallback(input: Any, filter_sizes: Any, out_backprop: Any, strides: Any, padding: Any, use_cudnn_on_gpu: Any, explicit_paddings: Any, data_format: Any, dilations: Any, name: Any, ctx: Any): ...
def conv2d_backprop_input(input_sizes: Any, filter: Any, out_backprop: Any, strides: Any, padding: Any, use_cudnn_on_gpu: bool = ..., explicit_paddings: Any = ..., data_format: str = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

Conv2DBackpropInput: Any

def conv2d_backprop_input_eager_fallback(input_sizes: Any, filter: Any, out_backprop: Any, strides: Any, padding: Any, use_cudnn_on_gpu: Any, explicit_paddings: Any, data_format: Any, dilations: Any, name: Any, ctx: Any): ...
def conv3d(input: Any, filter: Any, strides: Any, padding: Any, data_format: str = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

Conv3D: Any

def conv3d_eager_fallback(input: Any, filter: Any, strides: Any, padding: Any, data_format: Any, dilations: Any, name: Any, ctx: Any): ...
def conv3d_backprop_filter(input: Any, filter: Any, out_backprop: Any, strides: Any, padding: Any, dilations: Any = ..., name: Optional[Any] = ...): ...

Conv3DBackpropFilter: Any

def conv3d_backprop_filter_eager_fallback(input: Any, filter: Any, out_backprop: Any, strides: Any, padding: Any, dilations: Any, name: Any, ctx: Any): ...
def conv3d_backprop_filter_v2(input: Any, filter_sizes: Any, out_backprop: Any, strides: Any, padding: Any, data_format: str = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

Conv3DBackpropFilterV2: Any

def conv3d_backprop_filter_v2_eager_fallback(input: Any, filter_sizes: Any, out_backprop: Any, strides: Any, padding: Any, data_format: Any, dilations: Any, name: Any, ctx: Any): ...
def conv3d_backprop_input(input: Any, filter: Any, out_backprop: Any, strides: Any, padding: Any, dilations: Any = ..., name: Optional[Any] = ...): ...

Conv3DBackpropInput: Any

def conv3d_backprop_input_eager_fallback(input: Any, filter: Any, out_backprop: Any, strides: Any, padding: Any, dilations: Any, name: Any, ctx: Any): ...
def conv3d_backprop_input_v2(input_sizes: Any, filter: Any, out_backprop: Any, strides: Any, padding: Any, data_format: str = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

Conv3DBackpropInputV2: Any

def conv3d_backprop_input_v2_eager_fallback(input_sizes: Any, filter: Any, out_backprop: Any, strides: Any, padding: Any, data_format: Any, dilations: Any, name: Any, ctx: Any): ...
def data_format_dim_map(x: Any, src_format: str = ..., dst_format: str = ..., name: Optional[Any] = ...): ...

DataFormatDimMap: Any

def data_format_dim_map_eager_fallback(x: Any, src_format: Any, dst_format: Any, name: Any, ctx: Any): ...
def data_format_vec_permute(x: Any, src_format: str = ..., dst_format: str = ..., name: Optional[Any] = ...): ...

DataFormatVecPermute: Any

def data_format_vec_permute_eager_fallback(x: Any, src_format: Any, dst_format: Any, name: Any, ctx: Any): ...
def depthwise_conv2d_native(input: Any, filter: Any, strides: Any, padding: Any, data_format: str = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

DepthwiseConv2dNative: Any

def depthwise_conv2d_native_eager_fallback(input: Any, filter: Any, strides: Any, padding: Any, data_format: Any, dilations: Any, name: Any, ctx: Any): ...
def depthwise_conv2d_native_backprop_filter(input: Any, filter_sizes: Any, out_backprop: Any, strides: Any, padding: Any, data_format: str = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

DepthwiseConv2dNativeBackpropFilter: Any

def depthwise_conv2d_native_backprop_filter_eager_fallback(input: Any, filter_sizes: Any, out_backprop: Any, strides: Any, padding: Any, data_format: Any, dilations: Any, name: Any, ctx: Any): ...
def depthwise_conv2d_native_backprop_input(input_sizes: Any, filter: Any, out_backprop: Any, strides: Any, padding: Any, data_format: str = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

DepthwiseConv2dNativeBackpropInput: Any

def depthwise_conv2d_native_backprop_input_eager_fallback(input_sizes: Any, filter: Any, out_backprop: Any, strides: Any, padding: Any, data_format: Any, dilations: Any, name: Any, ctx: Any): ...
def dilation2d(input: Any, filter: Any, strides: Any, rates: Any, padding: Any, name: Optional[Any] = ...): ...

Dilation2D: Any

def dilation2d_eager_fallback(input: Any, filter: Any, strides: Any, rates: Any, padding: Any, name: Any, ctx: Any): ...
def dilation2d_backprop_filter(input: Any, filter: Any, out_backprop: Any, strides: Any, rates: Any, padding: Any, name: Optional[Any] = ...): ...

Dilation2DBackpropFilter: Any

def dilation2d_backprop_filter_eager_fallback(input: Any, filter: Any, out_backprop: Any, strides: Any, rates: Any, padding: Any, name: Any, ctx: Any): ...
def dilation2d_backprop_input(input: Any, filter: Any, out_backprop: Any, strides: Any, rates: Any, padding: Any, name: Optional[Any] = ...): ...

Dilation2DBackpropInput: Any

def dilation2d_backprop_input_eager_fallback(input: Any, filter: Any, out_backprop: Any, strides: Any, rates: Any, padding: Any, name: Any, ctx: Any): ...
def elu(features: Any, name: Optional[Any] = ...): ...

Elu: Any

def elu_eager_fallback(features: Any, name: Any, ctx: Any): ...
def elu_grad(gradients: Any, outputs: Any, name: Optional[Any] = ...): ...

EluGrad: Any

def elu_grad_eager_fallback(gradients: Any, outputs: Any, name: Any, ctx: Any): ...

_FractionalAvgPoolOutput = namedtuple('FractionalAvgPool', ['output', 'row_pooling_sequence', 'col_pooling_sequence'])

def fractional_avg_pool(value: Any, pooling_ratio: Any, pseudo_random: bool = ..., overlapping: bool = ..., deterministic: bool = ..., seed: int = ..., seed2: int = ..., name: Optional[Any] = ...): ...

FractionalAvgPool: Any

def fractional_avg_pool_eager_fallback(value: Any, pooling_ratio: Any, pseudo_random: Any, overlapping: Any, deterministic: Any, seed: Any, seed2: Any, name: Any, ctx: Any): ...
def fractional_avg_pool_grad(orig_input_tensor_shape: Any, out_backprop: Any, row_pooling_sequence: Any, col_pooling_sequence: Any, overlapping: bool = ..., name: Optional[Any] = ...): ...

FractionalAvgPoolGrad: Any

def fractional_avg_pool_grad_eager_fallback(orig_input_tensor_shape: Any, out_backprop: Any, row_pooling_sequence: Any, col_pooling_sequence: Any, overlapping: Any, name: Any, ctx: Any): ...

_FractionalMaxPoolOutput = namedtuple('FractionalMaxPool', ['output', 'row_pooling_sequence', 'col_pooling_sequence'])

def fractional_max_pool(value: Any, pooling_ratio: Any, pseudo_random: bool = ..., overlapping: bool = ..., deterministic: bool = ..., seed: int = ..., seed2: int = ..., name: Optional[Any] = ...): ...

FractionalMaxPool: Any

def fractional_max_pool_eager_fallback(value: Any, pooling_ratio: Any, pseudo_random: Any, overlapping: Any, deterministic: Any, seed: Any, seed2: Any, name: Any, ctx: Any): ...
def fractional_max_pool_grad(orig_input: Any, orig_output: Any, out_backprop: Any, row_pooling_sequence: Any, col_pooling_sequence: Any, overlapping: bool = ..., name: Optional[Any] = ...): ...

FractionalMaxPoolGrad: Any

def fractional_max_pool_grad_eager_fallback(orig_input: Any, orig_output: Any, out_backprop: Any, row_pooling_sequence: Any, col_pooling_sequence: Any, overlapping: Any, name: Any, ctx: Any): ...

_FusedBatchNormOutput = namedtuple('FusedBatchNorm', ['y', 'batch_mean', 'batch_variance', 'reserve_space_1', 'reserve_space_2'])
FusedBatchNorm: Any

_FusedBatchNormGradOutput = namedtuple('FusedBatchNormGrad', ['x_backprop', 'scale_backprop', 'offset_backprop', 'reserve_space_3', 'reserve_space_4'])

def fused_batch_norm_grad(y_backprop: Any, x: Any, scale: Any, reserve_space_1: Any, reserve_space_2: Any, epsilon: float = ..., data_format: str = ..., is_training: bool = ..., name: Optional[Any] = ...): ...

FusedBatchNormGrad: Any

def fused_batch_norm_grad_eager_fallback(y_backprop: Any, x: Any, scale: Any, reserve_space_1: Any, reserve_space_2: Any, epsilon: Any, data_format: Any, is_training: Any, name: Any, ctx: Any): ...

_FusedBatchNormGradV2Output = namedtuple('FusedBatchNormGradV2', ['x_backprop', 'scale_backprop', 'offset_backprop', 'reserve_space_3', 'reserve_space_4'])

def fused_batch_norm_grad_v2(y_backprop: Any, x: Any, scale: Any, reserve_space_1: Any, reserve_space_2: Any, epsilon: float = ..., data_format: str = ..., is_training: bool = ..., name: Optional[Any] = ...): ...

FusedBatchNormGradV2: Any

def fused_batch_norm_grad_v2_eager_fallback(y_backprop: Any, x: Any, scale: Any, reserve_space_1: Any, reserve_space_2: Any, epsilon: Any, data_format: Any, is_training: Any, name: Any, ctx: Any): ...

_FusedBatchNormGradV3Output = namedtuple('FusedBatchNormGradV3', ['x_backprop', 'scale_backprop', 'offset_backprop', 'reserve_space_4', 'reserve_space_5'])

def fused_batch_norm_grad_v3(y_backprop: Any, x: Any, scale: Any, reserve_space_1: Any, reserve_space_2: Any, reserve_space_3: Any, epsilon: float = ..., data_format: str = ..., is_training: bool = ..., name: Optional[Any] = ...): ...

FusedBatchNormGradV3: Any

def fused_batch_norm_grad_v3_eager_fallback(y_backprop: Any, x: Any, scale: Any, reserve_space_1: Any, reserve_space_2: Any, reserve_space_3: Any, epsilon: Any, data_format: Any, is_training: Any, name: Any, ctx: Any): ...

_FusedBatchNormV2Output = namedtuple('FusedBatchNormV2', ['y', 'batch_mean', 'batch_variance', 'reserve_space_1', 'reserve_space_2'])

def fused_batch_norm_v2(x: Any, scale: Any, offset: Any, mean: Any, variance: Any, epsilon: float = ..., exponential_avg_factor: int = ..., data_format: str = ..., is_training: bool = ..., name: Optional[Any] = ...): ...

FusedBatchNormV2: Any

def fused_batch_norm_v2_eager_fallback(x: Any, scale: Any, offset: Any, mean: Any, variance: Any, epsilon: Any, exponential_avg_factor: Any, data_format: Any, is_training: Any, name: Any, ctx: Any): ...

_FusedBatchNormV3Output = namedtuple('FusedBatchNormV3', ['y', 'batch_mean', 'batch_variance', 'reserve_space_1', 'reserve_space_2', 'reserve_space_3'])

def fused_batch_norm_v3(x: Any, scale: Any, offset: Any, mean: Any, variance: Any, epsilon: float = ..., exponential_avg_factor: int = ..., data_format: str = ..., is_training: bool = ..., name: Optional[Any] = ...): ...

FusedBatchNormV3: Any

def fused_batch_norm_v3_eager_fallback(x: Any, scale: Any, offset: Any, mean: Any, variance: Any, epsilon: Any, exponential_avg_factor: Any, data_format: Any, is_training: Any, name: Any, ctx: Any): ...
def fused_pad_conv2d(input: Any, paddings: Any, filter: Any, mode: Any, strides: Any, padding: Any, name: Optional[Any] = ...): ...

FusedPadConv2D: Any

def fused_pad_conv2d_eager_fallback(input: Any, paddings: Any, filter: Any, mode: Any, strides: Any, padding: Any, name: Any, ctx: Any): ...
def fused_resize_and_pad_conv2d(input: Any, size: Any, paddings: Any, filter: Any, mode: Any, strides: Any, padding: Any, resize_align_corners: bool = ..., name: Optional[Any] = ...): ...

FusedResizeAndPadConv2D: Any

def fused_resize_and_pad_conv2d_eager_fallback(input: Any, size: Any, paddings: Any, filter: Any, mode: Any, strides: Any, padding: Any, resize_align_corners: Any, name: Any, ctx: Any): ...
def in_top_k(predictions: Any, targets: Any, k: Any, name: Optional[Any] = ...): ...

InTopK: Any

def in_top_k_eager_fallback(predictions: Any, targets: Any, k: Any, name: Any, ctx: Any): ...
def in_top_kv2(predictions: Any, targets: Any, k: Any, name: Optional[Any] = ...): ...

InTopKV2: Any

def in_top_kv2_eager_fallback(predictions: Any, targets: Any, k: Any, name: Any, ctx: Any): ...
def l2_loss(t: Any, name: Optional[Any] = ...): ...

L2Loss: Any

def l2_loss_eager_fallback(t: Any, name: Any, ctx: Any): ...
def lrn(input: Any, depth_radius: int = ..., bias: int = ..., alpha: int = ..., beta: float = ..., name: Optional[Any] = ...): ...

LRN: Any

def lrn_eager_fallback(input: Any, depth_radius: Any, bias: Any, alpha: Any, beta: Any, name: Any, ctx: Any): ...
def lrn_grad(input_grads: Any, input_image: Any, output_image: Any, depth_radius: int = ..., bias: int = ..., alpha: int = ..., beta: float = ..., name: Optional[Any] = ...): ...

LRNGrad: Any

def lrn_grad_eager_fallback(input_grads: Any, input_image: Any, output_image: Any, depth_radius: Any, bias: Any, alpha: Any, beta: Any, name: Any, ctx: Any): ...
def leaky_relu(features: Any, alpha: float = ..., name: Optional[Any] = ...): ...

LeakyRelu: Any

def leaky_relu_eager_fallback(features: Any, alpha: Any, name: Any, ctx: Any): ...
def leaky_relu_grad(gradients: Any, features: Any, alpha: float = ..., name: Optional[Any] = ...): ...

LeakyReluGrad: Any

def leaky_relu_grad_eager_fallback(gradients: Any, features: Any, alpha: Any, name: Any, ctx: Any): ...
def log_softmax(logits: Any, name: Optional[Any] = ...): ...

LogSoftmax: Any

def log_softmax_eager_fallback(logits: Any, name: Any, ctx: Any): ...
def max_pool(input: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

MaxPool: Any

def max_pool_eager_fallback(input: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def max_pool3d(input: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

MaxPool3D: Any

def max_pool3d_eager_fallback(input: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def max_pool3d_grad(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

MaxPool3DGrad: Any

def max_pool3d_grad_eager_fallback(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def max_pool3d_grad_grad(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

MaxPool3DGradGrad: Any

def max_pool3d_grad_grad_eager_fallback(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def max_pool_grad(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

MaxPoolGrad: Any

def max_pool_grad_eager_fallback(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def max_pool_grad_grad(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

MaxPoolGradGrad: Any

def max_pool_grad_grad_eager_fallback(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def max_pool_grad_grad_v2(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

MaxPoolGradGradV2: Any

def max_pool_grad_grad_v2_eager_fallback(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def max_pool_grad_grad_with_argmax(input: Any, grad: Any, argmax: Any, ksize: Any, strides: Any, padding: Any, include_batch_in_index: bool = ..., name: Optional[Any] = ...): ...

MaxPoolGradGradWithArgmax: Any

def max_pool_grad_grad_with_argmax_eager_fallback(input: Any, grad: Any, argmax: Any, ksize: Any, strides: Any, padding: Any, include_batch_in_index: Any, name: Any, ctx: Any): ...
def max_pool_grad_v2(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

MaxPoolGradV2: Any

def max_pool_grad_v2_eager_fallback(orig_input: Any, orig_output: Any, grad: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...
def max_pool_grad_with_argmax(input: Any, grad: Any, argmax: Any, ksize: Any, strides: Any, padding: Any, include_batch_in_index: bool = ..., name: Optional[Any] = ...): ...

MaxPoolGradWithArgmax: Any

def max_pool_grad_with_argmax_eager_fallback(input: Any, grad: Any, argmax: Any, ksize: Any, strides: Any, padding: Any, include_batch_in_index: Any, name: Any, ctx: Any): ...
def max_pool_v2(input: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...

MaxPoolV2: Any

def max_pool_v2_eager_fallback(input: Any, ksize: Any, strides: Any, padding: Any, data_format: Any, name: Any, ctx: Any): ...

_MaxPoolWithArgmaxOutput = namedtuple('MaxPoolWithArgmax', ['output', 'argmax'])

def max_pool_with_argmax(input: Any, ksize: Any, strides: Any, padding: Any, Targmax: Any = ..., include_batch_in_index: bool = ..., name: Optional[Any] = ...): ...

MaxPoolWithArgmax: Any

def max_pool_with_argmax_eager_fallback(input: Any, ksize: Any, strides: Any, padding: Any, Targmax: Any, include_batch_in_index: Any, name: Any, ctx: Any): ...
def nth_element(input: Any, n: Any, reverse: bool = ..., name: Optional[Any] = ...): ...

NthElement: Any

def nth_element_eager_fallback(input: Any, n: Any, reverse: Any, name: Any, ctx: Any): ...

_QuantizedAvgPoolOutput = namedtuple('QuantizedAvgPool', ['output', 'min_output', 'max_output'])

def quantized_avg_pool(input: Any, min_input: Any, max_input: Any, ksize: Any, strides: Any, padding: Any, name: Optional[Any] = ...): ...

QuantizedAvgPool: Any

def quantized_avg_pool_eager_fallback(input: Any, min_input: Any, max_input: Any, ksize: Any, strides: Any, padding: Any, name: Any, ctx: Any): ...

_QuantizedBatchNormWithGlobalNormalizationOutput = namedtuple('QuantizedBatchNormWithGlobalNormalization', ['result', 'result_min', 'result_max'])

def quantized_batch_norm_with_global_normalization(t: Any, t_min: Any, t_max: Any, m: Any, m_min: Any, m_max: Any, v: Any, v_min: Any, v_max: Any, beta: Any, beta_min: Any, beta_max: Any, gamma: Any, gamma_min: Any, gamma_max: Any, out_type: Any, variance_epsilon: Any, scale_after_normalization: Any, name: Optional[Any] = ...): ...

QuantizedBatchNormWithGlobalNormalization: Any

def quantized_batch_norm_with_global_normalization_eager_fallback(t: Any, t_min: Any, t_max: Any, m: Any, m_min: Any, m_max: Any, v: Any, v_min: Any, v_max: Any, beta: Any, beta_min: Any, beta_max: Any, gamma: Any, gamma_min: Any, gamma_max: Any, out_type: Any, variance_epsilon: Any, scale_after_normalization: Any, name: Any, ctx: Any): ...

_QuantizedBiasAddOutput = namedtuple('QuantizedBiasAdd', ['output', 'min_out', 'max_out'])

def quantized_bias_add(input: Any, bias: Any, min_input: Any, max_input: Any, min_bias: Any, max_bias: Any, out_type: Any, name: Optional[Any] = ...): ...

QuantizedBiasAdd: Any

def quantized_bias_add_eager_fallback(input: Any, bias: Any, min_input: Any, max_input: Any, min_bias: Any, max_bias: Any, out_type: Any, name: Any, ctx: Any): ...

_QuantizedConv2DOutput = namedtuple('QuantizedConv2D', ['output', 'min_output', 'max_output'])

def quantized_conv2d(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2D: Any

def quantized_conv2d_eager_fallback(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, name: Any, ctx: Any): ...

_QuantizedConv2DAndReluOutput = namedtuple('QuantizedConv2DAndRelu', ['output', 'min_output', 'max_output'])

def quantized_conv2d_and_relu(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DAndRelu: Any

def quantized_conv2d_and_relu_eager_fallback(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedConv2DAndReluAndRequantizeOutput = namedtuple('QuantizedConv2DAndReluAndRequantize', ['output', 'min_output', 'max_output'])

def quantized_conv2d_and_relu_and_requantize(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DAndReluAndRequantize: Any

def quantized_conv2d_and_relu_and_requantize_eager_fallback(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedConv2DAndRequantizeOutput = namedtuple('QuantizedConv2DAndRequantize', ['output', 'min_output', 'max_output'])

def quantized_conv2d_and_requantize(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DAndRequantize: Any

def quantized_conv2d_and_requantize_eager_fallback(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedConv2DPerChannelOutput = namedtuple('QuantizedConv2DPerChannel', ['output', 'min_output', 'max_output'])

def quantized_conv2d_per_channel(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DPerChannel: Any

def quantized_conv2d_per_channel_eager_fallback(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, name: Any, ctx: Any): ...

_QuantizedConv2DWithBiasOutput = namedtuple('QuantizedConv2DWithBias', ['output', 'min_output', 'max_output'])

def quantized_conv2d_with_bias(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DWithBias: Any

def quantized_conv2d_with_bias_eager_fallback(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedConv2DWithBiasAndReluOutput = namedtuple('QuantizedConv2DWithBiasAndRelu', ['output', 'min_output', 'max_output'])

def quantized_conv2d_with_bias_and_relu(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DWithBiasAndRelu: Any

def quantized_conv2d_with_bias_and_relu_eager_fallback(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedConv2DWithBiasAndReluAndRequantizeOutput = namedtuple('QuantizedConv2DWithBiasAndReluAndRequantize', ['output', 'min_output', 'max_output'])

def quantized_conv2d_with_bias_and_relu_and_requantize(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DWithBiasAndReluAndRequantize: Any

def quantized_conv2d_with_bias_and_relu_and_requantize_eager_fallback(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedConv2DWithBiasAndRequantizeOutput = namedtuple('QuantizedConv2DWithBiasAndRequantize', ['output', 'min_output', 'max_output'])

def quantized_conv2d_with_bias_and_requantize(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DWithBiasAndRequantize: Any

def quantized_conv2d_with_bias_and_requantize_eager_fallback(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedConv2DWithBiasSignedSumAndReluAndRequantizeOutput = namedtuple('QuantizedConv2DWithBiasSignedSumAndReluAndRequantize', ['output', 'min_output', 'max_output'])

def quantized_conv2d_with_bias_signed_sum_and_relu_and_requantize(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, summand: Any, min_summand: Any, max_summand: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DWithBiasSignedSumAndReluAndRequantize: Any

def quantized_conv2d_with_bias_signed_sum_and_relu_and_requantize_eager_fallback(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, summand: Any, min_summand: Any, max_summand: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedConv2DWithBiasSumAndReluOutput = namedtuple('QuantizedConv2DWithBiasSumAndRelu', ['output', 'min_output', 'max_output'])

def quantized_conv2d_with_bias_sum_and_relu(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, summand: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DWithBiasSumAndRelu: Any

def quantized_conv2d_with_bias_sum_and_relu_eager_fallback(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, summand: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedConv2DWithBiasSumAndReluAndRequantizeOutput = namedtuple('QuantizedConv2DWithBiasSumAndReluAndRequantize', ['output', 'min_output', 'max_output'])

def quantized_conv2d_with_bias_sum_and_relu_and_requantize(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, summand: Any, min_summand: Any, max_summand: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedConv2DWithBiasSumAndReluAndRequantize: Any

def quantized_conv2d_with_bias_sum_and_relu_and_requantize_eager_fallback(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, summand: Any, min_summand: Any, max_summand: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedDepthwiseConv2DOutput = namedtuple('QuantizedDepthwiseConv2D', ['output', 'min_output', 'max_output'])

def quantized_depthwise_conv2d(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

QuantizedDepthwiseConv2D: Any

def quantized_depthwise_conv2d_eager_fallback(input: Any, filter: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, name: Any, ctx: Any): ...

_QuantizedDepthwiseConv2DWithBiasOutput = namedtuple('QuantizedDepthwiseConv2DWithBias', ['output', 'min_output', 'max_output'])

def quantized_depthwise_conv2d_with_bias(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., name: Optional[Any] = ...): ...

QuantizedDepthwiseConv2DWithBias: Any

def quantized_depthwise_conv2d_with_bias_eager_fallback(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, name: Any, ctx: Any): ...

_QuantizedDepthwiseConv2DWithBiasAndReluOutput = namedtuple('QuantizedDepthwiseConv2DWithBiasAndRelu', ['output', 'min_output', 'max_output'])

def quantized_depthwise_conv2d_with_bias_and_relu(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedDepthwiseConv2DWithBiasAndRelu: Any

def quantized_depthwise_conv2d_with_bias_and_relu_eager_fallback(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedDepthwiseConv2DWithBiasAndReluAndRequantizeOutput = namedtuple('QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize', ['output', 'min_output', 'max_output'])

def quantized_depthwise_conv2d_with_bias_and_relu_and_requantize(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, strides: Any, padding: Any, out_type: Any = ..., dilations: Any = ..., padding_list: Any = ..., name: Optional[Any] = ...): ...

QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize: Any

def quantized_depthwise_conv2d_with_bias_and_relu_and_requantize_eager_fallback(input: Any, filter: Any, bias: Any, min_input: Any, max_input: Any, min_filter: Any, max_filter: Any, min_freezed_output: Any, max_freezed_output: Any, strides: Any, padding: Any, out_type: Any, dilations: Any, padding_list: Any, name: Any, ctx: Any): ...

_QuantizedMatMulWithBiasOutput = namedtuple('QuantizedMatMulWithBias', ['out', 'min_out', 'max_out'])

def quantized_mat_mul_with_bias(a: Any, b: Any, bias: Any, min_a: Any, max_a: Any, min_b: Any, max_b: Any, Toutput: Any = ..., transpose_a: bool = ..., transpose_b: bool = ..., input_quant_mode: str = ..., name: Optional[Any] = ...): ...

QuantizedMatMulWithBias: Any

def quantized_mat_mul_with_bias_eager_fallback(a: Any, b: Any, bias: Any, min_a: Any, max_a: Any, min_b: Any, max_b: Any, Toutput: Any, transpose_a: Any, transpose_b: Any, input_quant_mode: Any, name: Any, ctx: Any): ...
def quantized_mat_mul_with_bias_and_dequantize(a: Any, b: Any, bias: Any, min_a: Any, max_a: Any, min_b: Any, max_b: Any, min_freezed_output: Any, max_freezed_output: Any, Toutput: Any, transpose_a: bool = ..., transpose_b: bool = ..., input_quant_mode: str = ..., name: Optional[Any] = ...): ...

QuantizedMatMulWithBiasAndDequantize: Any

def quantized_mat_mul_with_bias_and_dequantize_eager_fallback(a: Any, b: Any, bias: Any, min_a: Any, max_a: Any, min_b: Any, max_b: Any, min_freezed_output: Any, max_freezed_output: Any, Toutput: Any, transpose_a: Any, transpose_b: Any, input_quant_mode: Any, name: Any, ctx: Any): ...

_QuantizedMatMulWithBiasAndReluOutput = namedtuple('QuantizedMatMulWithBiasAndRelu', ['out', 'min_out', 'max_out'])

def quantized_mat_mul_with_bias_and_relu(a: Any, b: Any, bias: Any, min_a: Any, max_a: Any, min_b: Any, max_b: Any, Toutput: Any = ..., transpose_a: bool = ..., transpose_b: bool = ..., input_quant_mode: str = ..., name: Optional[Any] = ...): ...

QuantizedMatMulWithBiasAndRelu: Any

def quantized_mat_mul_with_bias_and_relu_eager_fallback(a: Any, b: Any, bias: Any, min_a: Any, max_a: Any, min_b: Any, max_b: Any, Toutput: Any, transpose_a: Any, transpose_b: Any, input_quant_mode: Any, name: Any, ctx: Any): ...

_QuantizedMatMulWithBiasAndReluAndRequantizeOutput = namedtuple('QuantizedMatMulWithBiasAndReluAndRequantize', ['out', 'min_out', 'max_out'])

def quantized_mat_mul_with_bias_and_relu_and_requantize(a: Any, b: Any, bias: Any, min_a: Any, max_a: Any, min_b: Any, max_b: Any, min_freezed_output: Any, max_freezed_output: Any, Toutput: Any = ..., transpose_a: bool = ..., transpose_b: bool = ..., input_quant_mode: str = ..., name: Optional[Any] = ...): ...

QuantizedMatMulWithBiasAndReluAndRequantize: Any

def quantized_mat_mul_with_bias_and_relu_and_requantize_eager_fallback(a: Any, b: Any, bias: Any, min_a: Any, max_a: Any, min_b: Any, max_b: Any, min_freezed_output: Any, max_freezed_output: Any, Toutput: Any, transpose_a: Any, transpose_b: Any, input_quant_mode: Any, name: Any, ctx: Any): ...

_QuantizedMatMulWithBiasAndRequantizeOutput = namedtuple('QuantizedMatMulWithBiasAndRequantize', ['out', 'min_out', 'max_out'])

def quantized_mat_mul_with_bias_and_requantize(a: Any, b: Any, bias: Any, min_a: Any, max_a: Any, min_b: Any, max_b: Any, min_freezed_output: Any, max_freezed_output: Any, Toutput: Any = ..., transpose_a: bool = ..., transpose_b: bool = ..., input_quant_mode: str = ..., name: Optional[Any] = ...): ...

QuantizedMatMulWithBiasAndRequantize: Any

def quantized_mat_mul_with_bias_and_requantize_eager_fallback(a: Any, b: Any, bias: Any, min_a: Any, max_a: Any, min_b: Any, max_b: Any, min_freezed_output: Any, max_freezed_output: Any, Toutput: Any, transpose_a: Any, transpose_b: Any, input_quant_mode: Any, name: Any, ctx: Any): ...

_QuantizedMaxPoolOutput = namedtuple('QuantizedMaxPool', ['output', 'min_output', 'max_output'])

def quantized_max_pool(input: Any, min_input: Any, max_input: Any, ksize: Any, strides: Any, padding: Any, name: Optional[Any] = ...): ...

QuantizedMaxPool: Any

def quantized_max_pool_eager_fallback(input: Any, min_input: Any, max_input: Any, ksize: Any, strides: Any, padding: Any, name: Any, ctx: Any): ...

_QuantizedReluOutput = namedtuple('QuantizedRelu', ['activations', 'min_activations', 'max_activations'])

def quantized_relu(features: Any, min_features: Any, max_features: Any, out_type: Any = ..., name: Optional[Any] = ...): ...

QuantizedRelu: Any

def quantized_relu_eager_fallback(features: Any, min_features: Any, max_features: Any, out_type: Any, name: Any, ctx: Any): ...

_QuantizedRelu6Output = namedtuple('QuantizedRelu6', ['activations', 'min_activations', 'max_activations'])

def quantized_relu6(features: Any, min_features: Any, max_features: Any, out_type: Any = ..., name: Optional[Any] = ...): ...

QuantizedRelu6: Any

def quantized_relu6_eager_fallback(features: Any, min_features: Any, max_features: Any, out_type: Any, name: Any, ctx: Any): ...

_QuantizedReluXOutput = namedtuple('QuantizedReluX', ['activations', 'min_activations', 'max_activations'])

def quantized_relu_x(features: Any, max_value: Any, min_features: Any, max_features: Any, out_type: Any = ..., name: Optional[Any] = ...): ...

QuantizedReluX: Any

def quantized_relu_x_eager_fallback(features: Any, max_value: Any, min_features: Any, max_features: Any, out_type: Any, name: Any, ctx: Any): ...
def relu(features: Any, name: Optional[Any] = ...): ...

Relu: Any

def relu_eager_fallback(features: Any, name: Any, ctx: Any): ...
def relu6(features: Any, name: Optional[Any] = ...): ...

Relu6: Any

def relu6_eager_fallback(features: Any, name: Any, ctx: Any): ...
def relu6_grad(gradients: Any, features: Any, name: Optional[Any] = ...): ...

Relu6Grad: Any

def relu6_grad_eager_fallback(gradients: Any, features: Any, name: Any, ctx: Any): ...
def relu_grad(gradients: Any, features: Any, name: Optional[Any] = ...): ...

ReluGrad: Any

def relu_grad_eager_fallback(gradients: Any, features: Any, name: Any, ctx: Any): ...
def selu(features: Any, name: Optional[Any] = ...): ...

Selu: Any

def selu_eager_fallback(features: Any, name: Any, ctx: Any): ...
def selu_grad(gradients: Any, outputs: Any, name: Optional[Any] = ...): ...

SeluGrad: Any

def selu_grad_eager_fallback(gradients: Any, outputs: Any, name: Any, ctx: Any): ...
def softmax(logits: Any, name: Optional[Any] = ...): ...

Softmax: Any

def softmax_eager_fallback(logits: Any, name: Any, ctx: Any): ...

_SoftmaxCrossEntropyWithLogitsOutput = namedtuple('SoftmaxCrossEntropyWithLogits', ['loss', 'backprop'])

def softmax_cross_entropy_with_logits(features: Any, labels: Any, name: Optional[Any] = ...): ...

SoftmaxCrossEntropyWithLogits: Any

def softmax_cross_entropy_with_logits_eager_fallback(features: Any, labels: Any, name: Any, ctx: Any): ...
def softplus(features: Any, name: Optional[Any] = ...): ...

Softplus: Any

def softplus_eager_fallback(features: Any, name: Any, ctx: Any): ...
def softplus_grad(gradients: Any, features: Any, name: Optional[Any] = ...): ...

SoftplusGrad: Any

def softplus_grad_eager_fallback(gradients: Any, features: Any, name: Any, ctx: Any): ...
def softsign(features: Any, name: Optional[Any] = ...): ...

Softsign: Any

def softsign_eager_fallback(features: Any, name: Any, ctx: Any): ...
def softsign_grad(gradients: Any, features: Any, name: Optional[Any] = ...): ...

SoftsignGrad: Any

def softsign_grad_eager_fallback(gradients: Any, features: Any, name: Any, ctx: Any): ...

_SparseSoftmaxCrossEntropyWithLogitsOutput = namedtuple('SparseSoftmaxCrossEntropyWithLogits', ['loss', 'backprop'])

def sparse_softmax_cross_entropy_with_logits(features: Any, labels: Any, name: Optional[Any] = ...): ...

SparseSoftmaxCrossEntropyWithLogits: Any

def sparse_softmax_cross_entropy_with_logits_eager_fallback(features: Any, labels: Any, name: Any, ctx: Any): ...

_TopKOutput = namedtuple('TopK', ['values', 'indices'])

def top_k(input: Any, k: Any, sorted: bool = ..., name: Optional[Any] = ...): ...

TopK: Any

def top_k_eager_fallback(input: Any, k: Any, sorted: Any, name: Any, ctx: Any): ...

_TopKV2Output = namedtuple('TopKV2', ['values', 'indices'])

def top_kv2(input: Any, k: Any, sorted: bool = ..., name: Optional[Any] = ...): ...

TopKV2: Any

def top_kv2_eager_fallback(input: Any, k: Any, sorted: Any, name: Any, ctx: Any): ...
