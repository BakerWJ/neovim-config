from tensorflow.core.protobuf import config_pb2 as config_pb2, rewriter_config_pb2 as rewriter_config_pb2, tensorflow_server_pb2 as tensorflow_server_pb2
from tensorflow.python.distribute import cross_device_utils as cross_device_utils, device_util as device_util, distribute_lib as distribute_lib, input_lib as input_lib, mirrored_strategy as mirrored_strategy, multi_worker_util as multi_worker_util, numpy_dataset as numpy_dataset, reduce_util as reduce_util, values as values
from tensorflow.python.distribute.cluster_resolver import SimpleClusterResolver as SimpleClusterResolver, TFConfigClusterResolver as TFConfigClusterResolver
from tensorflow.python.eager import context as context
from tensorflow.python.framework import ops as ops
from tensorflow.python.ops import array_ops as array_ops, collective_ops as collective_ops
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any, Optional

class CollectiveAllReduceStrategy(distribute_lib.Strategy):
    def __init__(self, communication: Any = ..., cluster_resolver: Optional[Any] = ...) -> None: ...
    def scope(self): ...

class CollectiveAllReduceStrategyV1(distribute_lib.StrategyV1):
    __doc__: Any = ...
    def __init__(self, communication: Any = ..., cluster_resolver: Optional[Any] = ...) -> None: ...

class CollectiveAllReduceExtended(mirrored_strategy.MirroredExtended):
    def __init__(self, container_strategy: Any, communication: Any, cluster_resolver: Any) -> None: ...
    @property
    def experimental_between_graph(self): ...
    @property
    def experimental_should_init(self): ...
    @property
    def should_checkpoint(self): ...
    @property
    def should_save_summary(self): ...
