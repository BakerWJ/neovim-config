from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver as ClusterResolver, format_master_url as format_master_url
from tensorflow.python.training.server_lib import ClusterSpec as ClusterSpec
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any, Optional

def expand_hostlist(hostlist: Any): ...
def expand_tasks_per_node(tasks_per_node: Any): ...
def get_num_slurm_tasks(): ...
def get_num_gpus(): ...

class SlurmClusterResolver(ClusterResolver):
    task_type: Any = ...
    task_id: Any = ...
    rpc_layer: Any = ...
    def __init__(self, jobs: Optional[Any] = ..., port_base: int = ..., gpus_per_node: Optional[Any] = ..., gpus_per_task: Optional[Any] = ..., tasks_per_node: Optional[Any] = ..., auto_set_gpu: bool = ..., rpc_layer: str = ...) -> None: ...
    def cluster_spec(self): ...
    def get_task_info(self): ...
    def master(self, task_type: Optional[Any] = ..., task_id: Optional[Any] = ..., rpc_layer: Optional[Any] = ...): ...
    def num_accelerators(self, task_type: Optional[Any] = ..., task_id: Optional[Any] = ..., config_proto: Optional[Any] = ...): ...
